{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from random import shuffle\n",
    "from itertools import product\n",
    "import multiprocessing as mp\n",
    "from math import fabs,sqrt,log,exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound(loss,L,lam):\n",
    "    '''\n",
    "    Calculate annoying parameters to estimate rho\n",
    "    '''\n",
    "        \n",
    "    R1 = 0.0\n",
    "    R2 = 0.0\n",
    "    Sp1 = 0.0\n",
    "    Sm1 = 0.0\n",
    "    Sp2 = 0.0\n",
    "    Sm2 = 0.0\n",
    "\n",
    "    for i in range(N+1):\n",
    "        # compute plus\n",
    "        alpha0 = L**i\n",
    "        alpha1 = i*L**(i-1)\n",
    "        alpha2 = i*(i-1)*L**(i-2)\n",
    "        R1 += alpha0\n",
    "        Sp1 += alpha1\n",
    "        Sp2 += alpha2\n",
    "        # compute minus\n",
    "        beta0 = 0.0\n",
    "        beta1 = 0.0\n",
    "        beta2 = 0.0\n",
    "        for k in range(i,N+1):\n",
    "            # compute forward difference\n",
    "            delta = 0.0\n",
    "            for j in range(k+1):\n",
    "                delta += comb_dict[k][j]*(-1)**(k-j)*loss(j/N)\n",
    "            # compute coefficient\n",
    "            beta0 += comb_dict[N][k]*comb_dict[k][i]*(N+1)*fabs(delta)/(2**k)/(L**i)\n",
    "            beta1 += comb_dict[N][k]*comb_dict[k][i]*(N+1)*(k-i)*fabs(delta)/(2**k)/(L**(i+1))\n",
    "            beta2 += comb_dict[N][k]*comb_dict[k][i]*(N+1)*(k-i)*(k-i-1)*fabs(delta)/(2**k)/(L**(i+2))\n",
    "        R2 += beta0\n",
    "        Sm1 += beta1\n",
    "        Sm2 += beta2\n",
    "        \n",
    "    gammap0 = max(Sp1+(2*R1+R2)*Sp2,1+Sp1)\n",
    "    gammam0 = max(Sm1+(2*R2+R1)*Sm2,1+Sm1)\n",
    "    gamma0_v1 = sqrt(3)/(N+1)*max(gammap0,gammam0)\n",
    "    \n",
    "    rho = max((2*R1+R2)*Sp2/(N+1),(2*R2+R1)*Sm2/(N+1))\n",
    "    gamma0_v2 = max(0,(fabs(1+(rho-lam)*(N+1))-1)/2/(N+1)+(rho-lam)/2)\n",
    "    print('R1: %.2f, R2: %.2f gamma: %.2f' %(R1,R2,gamma0_v2))\n",
    "    return R1,R2,rho,gamma0_v1,gamma0_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(loss,lam):\n",
    "    \n",
    "    # define loss function\n",
    "    if loss == 'hinge':\n",
    "        L = 2*sqrt(2/lam)\n",
    "        l = lambda x: max(0,1+L-2*L*x)\n",
    "    elif loss == 'logistic':\n",
    "        L = 2*sqrt(2*log(2)/lam)\n",
    "        l = lambda x:log(1+exp(L-2*L*x))\n",
    "    else:\n",
    "        print('Wrong loss function!')\n",
    "        return\n",
    "    \n",
    "    print('L: %f'%L)\n",
    "    \n",
    "    return l,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 2.828427\n",
      "R1: 279.48, R2: 51.74 gamma: 57762.02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(279.47518010647195,\n",
       " 51.73959660144271,\n",
       " 57763.0156976693,\n",
       " 100175.8317919486,\n",
       " 57762.0156976693)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lo,L = loss_func(loss,1)\n",
    "bound(lo,L,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_func(L,lam):\n",
    "    return lam/2*(L/2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_func(loss,L):\n",
    "    \n",
    "    if loss == 'hinge':\n",
    "        l = lambda x: max(0,1+L-2*L*x)\n",
    "    elif loss == 'logistic':\n",
    "        l = lambda x:log(1+exp(L-2*L*x))\n",
    "    else:\n",
    "        print('Wrong loss function!')\n",
    "    \n",
    "    B0 = 0.0\n",
    "    for k in range(N+1):\n",
    "        B0 += comb_dict[N][k]*l(k/N)\n",
    "        \n",
    "    return B0/2**N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomy(loss,lam,a,b,tol,max_iter):\n",
    "    fa = right_func(a,lam) - left_func(loss,a)\n",
    "    fb = right_func(b,lam) - left_func(loss,b)\n",
    "    if fa*fb > 0:\n",
    "        print('Wrong search!')\n",
    "        return\n",
    "    i = 1\n",
    "    while i<max_iter:\n",
    "        fa = right_func(a,lam) - left_func(loss,a)\n",
    "        fb = right_func(b,lam) - left_func(loss,b)\n",
    "        c = (a+b)/2\n",
    "        fc = right_func(c,lam) - left_func(loss,c)\n",
    "        if fc == 0 or (b - a)/2 < tol:\n",
    "            print('Found!')\n",
    "            return c\n",
    "        i += 1\n",
    "        if fa*fc > 0:\n",
    "            a = c+0.0\n",
    "        else:\n",
    "            b = c+0.0\n",
    "    print('Failed!')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(i,prod,L):\n",
    "    '''\n",
    "    Compute positive function and gradient information\n",
    "    \n",
    "    input:\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fpt - positive function value\n",
    "        gfpt - positive function gradient\n",
    "    '''\n",
    "    plus = L/2+prod\n",
    "    fpt = plus**i\n",
    "    gfpt = fpt*i/plus # no xt yet!\n",
    "    return fpt,gfpt              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(n, k):\n",
    "    '''\n",
    "    Compute combination\n",
    "    \n",
    "    input:\n",
    "        n - total number\n",
    "        k - number of chosen\n",
    "    \n",
    "    output:\n",
    "        c - number of combination\n",
    "    '''\n",
    "    return factorial(n) / factorial(k) / factorial(n - k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_dict = {0:{0:1},1:{0:1,1:1},2:{0:1,1:2,2:1},3:{0:1,1:3,2:3,3:1},4:{0:1,1:4,2:6,3:4,4:1},\n",
    "             5:{0:1,1:5,2:10,3:10,4:5,5:1},6:{0:1,1:6,2:15,3:20,4:15,5:6,6:1},\n",
    "             7:{0:1,1:7,2:21,3:35,4:35,5:21,6:7,7:1},8:{0:1,1:8,2:28,3:56,4:70,5:56,6:28,7:8,8:1},\n",
    "             9:{0:1,1:9,2:36,3:84,4:126,5:126,6:84,7:36,8:9,9:1},\n",
    "             10:{0:1,1:10,2:45,3:120,4:210,5:252,6:210,7:120,8:45,9:10,10:1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(loss,i,prod,L):\n",
    "    '''\n",
    "    Compute negative function and gradient information\n",
    "    \n",
    "    input:\n",
    "        loss - loss function\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fnt - negative function value\n",
    "        gfnt - negative function gradient\n",
    "    '''\n",
    "    minus = L/2-prod\n",
    "    #FNT = np.zeros(N+1-i)\n",
    "    #GFNT = np.zeros(N+1-i)\n",
    "    fnt = 0.0\n",
    "    gfnt = 0.0\n",
    "    # hfnt = 0.0\n",
    "    for k in range(i,N+1):\n",
    "        # compute forward difference\n",
    "        delta = 0.0\n",
    "        for j in range(k+1):\n",
    "            delta += comb_dict[k][j]*(-1)**(k-j)*loss(j/N)\n",
    "            \n",
    "        # compute coefficient\n",
    "        #beta = beta_dict[i][k-i]*delta/(2*L)**k*minus**(k-i)\n",
    "        beta = (comb_dict[N][k]*comb_dict[k][i]*(N+1)*delta/((2*L)**k))*(minus**(k-i))\n",
    "        # compute function value\n",
    "        fnt += beta\n",
    "        # compute gradient\n",
    "        gfnt += beta*(k-i)/minus  # no xt yet!\n",
    "        \n",
    "        # compute hessian\n",
    "        # hfnt += beta*(k-i)*(k-i-1)*(L/2-prod)**(k-i-2)\n",
    "    return fnt,gfnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_grad(gfpt,gfnt,yt,at,bt,alphat):\n",
    "    '''\n",
    "    Gradient with respect to w\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        gfpt - positive function gradient at t\n",
    "        fnt - negative function at t\n",
    "        gfnt - negative function gradient at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        alphat - alpha at t\n",
    "    output:\n",
    "        gradwt - gradient w.r.t. w at t\n",
    "    '''\n",
    "    if yt == 1:\n",
    "        gradwt = 2*(alphat - at)*gfpt\n",
    "    else:\n",
    "        gradwt = 2*(alphat - bt)*gfnt\n",
    "    return gradwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(wt,R):\n",
    "    '''\n",
    "    Projection\n",
    "    \n",
    "    input:\n",
    "        wt - w at t\n",
    "        R - radius\n",
    "        \n",
    "    output:\n",
    "        proj - projected wt\n",
    "    '''\n",
    "    norm = np.linalg.norm(wt)\n",
    "    if norm > R:\n",
    "        wt = wt/norm*R\n",
    "    return wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_grad(fpt,yt,at):\n",
    "    '''\n",
    "    Gradient with respect to a\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "    \n",
    "    output:\n",
    "        gradat - gradient w.r.t a at t\n",
    "    '''\n",
    "    gradat = 0.0 \n",
    "    if yt == 1:\n",
    "        gradat = 2*(at - fpt)\n",
    "    else:\n",
    "        gradat = 2*at\n",
    "    return gradat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_grad(fnt,yt,bt):\n",
    "    '''\n",
    "    Gradient with respect to b\n",
    "    \n",
    "    input:\n",
    "        fnt - negative function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        bt - b at t\n",
    "    \n",
    "    output:\n",
    "        gradbt - gradient w.r.t b at t\n",
    "    '''\n",
    "    gradbt = 0.0 \n",
    "    if yt == 1:\n",
    "        gradbt = 2*bt\n",
    "    else:\n",
    "        gradbt = 2*(bt - fnt)\n",
    "    return gradbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_grad(fpt,fnt,yt,alphat):\n",
    "    '''\n",
    "    Gradient with respect to alpha\n",
    "    '''\n",
    "    gradalphat = 0.0\n",
    "    if yt == 1:\n",
    "        gradalphat = -2*(alphat - fpt)\n",
    "    else:\n",
    "        gradalphat = -2*(alphat - fnt)\n",
    "    return gradalphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(folder,folders):\n",
    "    \n",
    "    if folder >= folders:\n",
    "        print('Exceed maximum folders!')\n",
    "        return\n",
    "    # load and split data\n",
    "    n,d = FEATURES.shape\n",
    "    \n",
    "    # regular portion of each folder\n",
    "    portion = round(n/folders)\n",
    "    start = portion*folder\n",
    "    stop = portion*(folder+1)\n",
    "    \n",
    "    if folders == 1:\n",
    "        train_list = [i for i in range(n)]\n",
    "        test_list = [i for i in range(n)]\n",
    "        \n",
    "    elif folders == 2:\n",
    "        if folder == 0:\n",
    "            train_list = [i for i in range(start)] + [i for i in range(stop,n)]\n",
    "            test_list = [i for i in range(start,stop)]\n",
    "        else:\n",
    "            train_list = [i for i in range(start)]\n",
    "            test_list = [i for i in range(start,n)]\n",
    "            \n",
    "    else:\n",
    "        if fabs(stop - n) < portion: # remainder occurs\n",
    "            train_list = [i for i in range(start)]\n",
    "            test_list = [i for i in range(start,n)]\n",
    "        else:\n",
    "            train_list = [i for i in range(start)] + [i for i in range(stop,n)]\n",
    "            test_list = [i for i in range(start,stop)]\n",
    "        \n",
    "    return train_list,test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox(eta,loss,index,L,R1,R2,gamma,lam,wj,aj,bj,alphaj,bwt,bat,bbt,balphat):\n",
    "    '''\n",
    "    perform proximal guided gradient descent when receive an sample\n",
    "    '''\n",
    "    prod = np.dot(wj,FEATURES[index])\n",
    "    fpt = np.zeros(N+1)\n",
    "    gfpt = np.zeros(N+1)\n",
    "    fnt = np.zeros(N+1)\n",
    "    gfnt = np.zeros(N+1)\n",
    "    gradwt = 0.0\n",
    "    gradat = 0.0\n",
    "    gradbt = 0.0\n",
    "    gradalphat = 0.0\n",
    "    for i in range(N+1):\n",
    "        fpt[i],gfpt[i] = pos(i,prod,L)\n",
    "        fnt[i],gfnt[i] = neg(loss,i,prod,L)\n",
    "        gradwt += w_grad(gfpt[i],gfnt[i],LABELS[index],aj[i],bj[i],alphaj[i])# accumulate i\n",
    "        gradat = a_grad(fpt[i],LABELS[index],aj[i])\n",
    "        gradbt = b_grad(fnt[i],LABELS[index],bj[i])\n",
    "        gradalphat = alpha_grad(fpt[i],fnt[i],LABELS[index],alphaj[i])\n",
    "        aj[i] = aj[i] - eta*(gradat/(2*(N+1))+gamma*(aj[i]-bat[i]))\n",
    "        bj[i] = bj[i] - eta*(gradbt/(2*(N+1))+gamma*(bj[i]-bbt[i]))\n",
    "        #aj[i] = (aj[i] / eta + gamma * bat[i] - gradat/(2*(N+1))) / (1 / eta + gamma)\n",
    "        #bj[i] = (bj[i] / eta + gamma * bbt[i] - gradbt/(2*(N+1))) / (1 / eta + gamma)\n",
    "        alphaj[i] = alphaj[i] + eta*gradalphat/(2*(N+1))\n",
    "        #alphaj[i] = (alphaj[i]/eta + (gradalphat+alphaj[i])/(2*(N+1))) / (1 / eta + gamma)\n",
    "    \n",
    "    wj = wj - eta*(gradwt*FEATURES[index]*LABELS[index]/(2*(N+1)) + lam*wj + gamma*(wj - bwt))\n",
    "    #wj = (wj/eta+gamma*bwt-gradwt*FEATURES[index]*LABELS[index]/(2*(N+1)))/(1 / eta + gamma+ lam)\n",
    "    wj = proj(wj,L/2)\n",
    "    aj = proj(aj,R1)\n",
    "    bj = proj(bj,R2)\n",
    "    alphaj = proj(alphaj,R1+R2)\n",
    "    \n",
    "    return wj,aj,bj,alphaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGSPD(t,loss,passing_list,L,R1,R2,gamma,lam,theta,c,bwt,bat,bbt,balphat):\n",
    "    '''\n",
    "    Proximally Guided Stochastic Primal Dual Algorithm\n",
    "    '''\n",
    "    # initialize inner loop variables\n",
    "    Wt = bwt+0.0\n",
    "    At = bat+0.0\n",
    "    Bt = bbt+0.0\n",
    "    ALPHAt = balphat+0.0\n",
    "    \n",
    "    BWt = 0.0\n",
    "    BAt = 0.0\n",
    "    BBt = 0.0\n",
    "    BALPHAt = 0.0\n",
    "    \n",
    "    ETAt = c/(t**theta)/gamma\n",
    "    \n",
    "    # inner loop update at j\n",
    "    for j in range(t):\n",
    "        # update inner loop variables\n",
    "        Wt,At,Bt,ALPHAt = prox(ETAt,loss,passing_list[j],L,R1,R2,gamma,lam,Wt,At,Bt,ALPHAt,bwt,bat,bbt,balphat)\n",
    "        BWt += Wt\n",
    "        BAt += At\n",
    "        BBt += Bt\n",
    "        BALPHAt += ALPHAt\n",
    "        \n",
    "    # update outer loop variables\n",
    "    bwt = BWt/t\n",
    "    bat = BAt/t\n",
    "    bbt = BBt/t\n",
    "    balphat = BALPHAt/t\n",
    "    \n",
    "    return bwt,bat,bbt,balphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(loss,train_list,test_list,L,R1,R2,gamma=0.01,lam=10,theta=0.5,c = 1):\n",
    "    '''\n",
    "    Run it to get results\n",
    "    '''\n",
    "    \n",
    "    # get dimensions of the data\n",
    "    num = len(train_list)\n",
    "    _,d = FEATURES.shape\n",
    "    \n",
    "    # initialize outer loop variables\n",
    "    WT = np.zeros(d) # d is the dimension of the features\n",
    "    AT = np.zeros(N+1)\n",
    "    BT = np.zeros(N+1)\n",
    "    ALPHAT = np.zeros(N+1)\n",
    "\n",
    "\n",
    "    # record auc\n",
    "    roc_auc = np.zeros(T)\n",
    "    # record time elapsed\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for t in range(1,T+1):    \n",
    "        \n",
    "        epoch = t // num\n",
    "        begin = (t*(t-1)//2)%num\n",
    "        end = (t*(t+1)//2)%num\n",
    "\n",
    "        if epoch < 1:\n",
    "            if begin < end:\n",
    "                tr_list = [i for i in range(begin,end)]\n",
    "            else: # need to think better\n",
    "                tr_list = [i for i in range(begin,num)] + [i for i in range(end)]\n",
    "        else:\n",
    "            if begin < end:\n",
    "                tr_list = [i for i in range(begin,num)] + [i for i in range(num)]*(epoch-1) + [i for i in range(end)]\n",
    "            else:\n",
    "                tr_list = [i for i in range(begin,num)] + [i for i in range(num)]*epoch + [i for i in range(end)]\n",
    "                \n",
    "        shuffle(tr_list) # shuffle works in place\n",
    "        \n",
    "        # update outer loop variables\n",
    "        WT,AT,BT,ALPHAT = PGSPD(t,loss,tr_list,L,R1,R2,gamma,lam,theta,c,WT,AT,BT,ALPHAT)   \n",
    "        \n",
    "        try:\n",
    "            roc_auc[t-1] = roc_auc_score(LABELS[test_list], np.dot(FEATURES[test_list],WT))\n",
    "        except ValueError:\n",
    "            print('Something is wrong bruh! Look at sum of WT: %f' %(sum(WT)))\n",
    "            return WT,AT,BT,ALPHAT,roc_auc\n",
    "        \n",
    "        if t%100 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('gamma: %.2f lam: %.2f theta: %.2f c: %.2f iteration: %d AUC: %.6f time eplapsed: %.2f' \n",
    "                  %(gamma,lam,theta,c,t,roc_auc[t-1],elapsed_time))\n",
    "            start_time = time.time()\n",
    "            \n",
    "    return WT,AT,BT,ALPHAT,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_run(para):\n",
    "    \n",
    "    folder,gamma,lam,theta,c,paras = para\n",
    "    training,testing,loss = paras\n",
    "    \n",
    "    # define loss function\n",
    "    lo,L = loss_func(loss,LAM[lam])\n",
    "    \n",
    "    # compute bound for a,b and alpha\n",
    "    R1,R2,_,_,_ = bound(lo,L,LAM[lam]) \n",
    "    \n",
    "    _,_,_,_,roc_auc = demo(lo,training,testing,L,R1,R2,gamma=GAMMA[gamma],lam=LAM[lam],theta=THETA[theta],c=C[c])\n",
    "    \n",
    "    return folder,gamma,lam,theta,c, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs(loss,folders=5,GAMMA=[0.01],LAM=[10.0],THETA=[0.25],C=[10.0]):\n",
    "    '''\n",
    "    Grid search! Wuss up fellas?!\n",
    "    And we are using multiprocessing, fancy!\n",
    "    '''\n",
    "    # number of cpu want to use\n",
    "    num_cpus = 15\n",
    "    # record auc\n",
    "    ROC_AUC = np.zeros((folders,len(GAMMA),len(LAM),len(THETA),len(C),T))\n",
    "    # record parameters\n",
    "    input_paras = []\n",
    "    # grid search prepare\n",
    "    for folder in range(folders):\n",
    "        training,testing = split(folder,folders)\n",
    "        paras = training,testing,loss\n",
    "        for gamma,lam,theta,c in product(range(len(GAMMA)),range(len(LAM)),range(len(THETA)),range(len(C))):\n",
    "            input_paras.append((folder,gamma,lam,theta,c,paras))\n",
    "    print('dataset: %s how many paras: %d' % (dataset,len(input_paras)))\n",
    "    # grid search run on multiprocessors\n",
    "    with mp.Pool(processes=num_cpus) as pool:\n",
    "        results_pool = pool.map(single_run,input_paras)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    # save results\n",
    "    for folder,gamma,lam,theta,c, roc_auc in results_pool:\n",
    "        ROC_AUC[folder,gamma,lam,theta,c] = roc_auc\n",
    "    return ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(x):\n",
    "    folders,GAMMA,LAM,THETA,C = x.shape\n",
    "\n",
    "    MEAN = np.zeros((GAMMA, LAM, THETA, C))\n",
    "    STD = np.zeros((GAMMA, LAM, THETA, C))\n",
    "\n",
    "    for gamma, lam, theta, c in product(range(GAMMA), range(LAM), range(THETA), range(C)):\n",
    "        MEAN[gamma, lam, theta, c] = np.mean(x[:, gamma, lam, theta, c])\n",
    "        STD[gamma, lam, theta, c] = np.std(x[:, gamma, lam, theta, c])\n",
    "\n",
    "    return MEAN,STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(loss,gamma=1,lam=10,theta=0.5,c = 1):\n",
    "    '''\n",
    "    Smooth output auc by averaging\n",
    "    '''\n",
    "    \n",
    "    num = len(LABELS)\n",
    "    training = [i for i in range(num)]\n",
    "    testing = [i for i in range(num)]\n",
    "    \n",
    "    # define loss function\n",
    "    lo,L = loss_func(loss,lam)\n",
    "    \n",
    "    # compute bound for a,b and alpha\n",
    "    R1,R2,_,_,_ = bound(lo,L,lam) \n",
    "    \n",
    "    _,_,_,_,roc_auc = demo(lo,training,testing,L,R1,R2,gamma=gamma,lam=lam,theta=theta,c=c)\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(ROC_AUC):\n",
    "    '''\n",
    "    Plot AUC\n",
    "    '''\n",
    "    for gamma,lam,theta,c in product(range(len(GAMMA)),range(len(LAM)),range(len(THETA)),range(len(C))):\n",
    "        plt.plot(range(T),ROC_AUC[0,gamma,lam,theta,c],label=r'$\\gamma$ = %d'%GAMMA[gamma])\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.legend()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from hdf5 file\n",
    "i = 1\n",
    "dataset = 'german'\n",
    "hf = h5py.File('%s.h5' %(dataset), 'r')\n",
    "FEATURES = hf['FEATURES'][:]\n",
    "LABELS = hf['LABELS'][:]\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper parameters\n",
    "N=5\n",
    "T=1000\n",
    "folders=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "GAMMA = [10,100]\n",
    "LAM = [10]\n",
    "THETA = [0.5]\n",
    "C = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper parameters\n",
    "loss = 'hinge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: german how many paras: 4\n",
      "L: 0.894427\n",
      "L: 0.894427\n",
      "L: 0.894427\n",
      "L: 0.894427\n",
      "R1: 4.62, R2: 22.73 gamma: 156.70\n",
      "R1: 4.62, R2: 22.73 gamma: 156.70\n",
      "R1: 4.62, R2: 22.73 gamma: 156.70\n",
      "R1: 4.62, R2: 22.73 gamma: 156.70\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 100 AUC: 0.605637 time eplapsed: 5.30\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 100 AUC: 0.595730 time eplapsed: 6.03\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 100 AUC: 0.585145 time eplapsed: 6.86\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 100 AUC: 0.619719 time eplapsed: 9.13\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 200 AUC: 0.606562 time eplapsed: 15.85\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 200 AUC: 0.638272 time eplapsed: 15.55\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 200 AUC: 0.585448 time eplapsed: 15.25\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 200 AUC: 0.659571 time eplapsed: 15.73\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 300 AUC: 0.607796 time eplapsed: 18.92\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 300 AUC: 0.586175 time eplapsed: 18.14\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 300 AUC: 0.715922 time eplapsed: 18.84\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 300 AUC: 0.730110 time eplapsed: 19.28\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 400 AUC: 0.587064 time eplapsed: 20.86\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 400 AUC: 0.608250 time eplapsed: 21.12\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 400 AUC: 0.785229 time eplapsed: 21.43\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 400 AUC: 0.775134 time eplapsed: 20.82\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 500 AUC: 0.588437 time eplapsed: 23.47\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 500 AUC: 0.789290 time eplapsed: 23.49\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 500 AUC: 0.609393 time eplapsed: 24.42\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 500 AUC: 0.780197 time eplapsed: 23.00\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 600 AUC: 0.590074 time eplapsed: 26.11\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 600 AUC: 0.612097 time eplapsed: 26.15\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 600 AUC: 0.780806 time eplapsed: 26.67\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 600 AUC: 0.787801 time eplapsed: 27.40\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 700 AUC: 0.784280 time eplapsed: 27.68\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 700 AUC: 0.591063 time eplapsed: 29.04\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 700 AUC: 0.613186 time eplapsed: 29.19\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 700 AUC: 0.789162 time eplapsed: 27.55\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 800 AUC: 0.779917 time eplapsed: 28.78\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 800 AUC: 0.592619 time eplapsed: 30.53\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 800 AUC: 0.615473 time eplapsed: 31.26\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 800 AUC: 0.786821 time eplapsed: 30.27\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 900 AUC: 0.787189 time eplapsed: 32.74\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 900 AUC: 0.594477 time eplapsed: 33.06\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 900 AUC: 0.617596 time eplapsed: 33.54\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 900 AUC: 0.786495 time eplapsed: 34.01\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 1000 AUC: 0.782826 time eplapsed: 34.63\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 1000 AUC: 0.597527 time eplapsed: 35.99\n",
      "gamma: 100.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 1000 AUC: 0.620499 time eplapsed: 34.83\n",
      "gamma: 10.00 lam: 10.00 theta: 0.50 c: 1.00 iteration: 1000 AUC: 0.780306 time eplapsed: 34.49\n"
     ]
    }
   ],
   "source": [
    "x = gs(loss,folders=folders,GAMMA=GAMMA,LAM=LAM,THETA=THETA,C=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
