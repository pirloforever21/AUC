{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import torch\n",
    "from math import factorial\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(i,t,prod):\n",
    "    '''\n",
    "    Compute positive function and gradient information\n",
    "    \n",
    "    input:\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fpt - positive function value\n",
    "        gfpt - positive function gradient\n",
    "    '''\n",
    "    fpt = 0.0 \n",
    "    gfpt = 0.0 \n",
    "    fpt = (L/2+prod)**i # no xt yet!\n",
    "    gfpt = i*(L/2+prod)**(i-1) \n",
    "    return fpt,gfpt               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(n, k):\n",
    "    '''\n",
    "    Compute combination\n",
    "    \n",
    "    input:\n",
    "        n - total number\n",
    "        k - number of chosen\n",
    "    \n",
    "    output:\n",
    "        c - number of combination\n",
    "    '''\n",
    "    return factorial(n) / factorial(k) / factorial(n - k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(loss,i,t,prod):\n",
    "    '''\n",
    "    Compute negative function and gradient information\n",
    "    \n",
    "    input:\n",
    "        loss - loss function\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fnt - negative function value\n",
    "        gfnt - negative function gradient\n",
    "    '''\n",
    "    fnt = 0.0 # n stands for negative\n",
    "    gfnt = 0.0\n",
    "    for k in range(i,N+1):\n",
    "        # compute forward difference\n",
    "        delta = 0.0\n",
    "        for j in range(k+1):\n",
    "            delta += (-1)**(k-j)*comb(k,j)*loss(j/N)\n",
    "        # compute coefficient\n",
    "        beta = comb(N,k)*comb(k,i)*(N+1)*delta/(2*L)**k\n",
    "        # compute function value\n",
    "        fnt += beta*(L/2-prod)**(k-i)\n",
    "        # compute gradient\n",
    "        gfnt += beta*(k-i)*(L/2-prod)**(k-i-1)  # no xt yet!\n",
    "    return fnt,gfnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_hat(t,yt,ptm1):\n",
    "    '''\n",
    "    Approximate probability\n",
    "    \n",
    "    input:\n",
    "        t - iteration\n",
    "        yt - label at t\n",
    "        ptm1 - p at t-1\n",
    "    \n",
    "    output:\n",
    "        pt - p at t\n",
    "    '''\n",
    "    pt = (t*ptm1 + (yt+1)/2)/(t+1) # m stands for minus\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_hat(t,fpt,yt,ptm1,atm1):\n",
    "    '''\n",
    "    Approximate primal a\n",
    "    \n",
    "    input:\n",
    "        t - iteration\n",
    "        fpt - positive function at t\n",
    "        yt - sample label at t\n",
    "        ptm1 - p at t-1\n",
    "        atm1 - a at t-1\n",
    "    \n",
    "    output:\n",
    "        at - a at t\n",
    "    '''\n",
    "    at = (fpt*((yt+1)/2) + t*ptm1*atm1)/(t+1) # do not update pt yet!\n",
    "    return at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_hat(t,fmt,yt,ptm1,btm1):\n",
    "    '''\n",
    "    Approximate primal b\n",
    "    \n",
    "    input:\n",
    "        t - iteration\n",
    "        fmt - negative function at t\n",
    "        yt - sample label at t\n",
    "        ptm1 - p at t-1\n",
    "        btm1 - b at t-1\n",
    "    \n",
    "    output:\n",
    "        bt - b at t-1\n",
    "    '''\n",
    "    bt = (fmt*((-yt+1)/2) + t*(1-ptm1)*btm1)/(t+1) # indicator of y=-1!\n",
    "    return bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_step(t,at,bt):\n",
    "    '''\n",
    "    Compute dual alpha\n",
    "    \n",
    "    input:\n",
    "        t - iteration\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        \n",
    "    output:\n",
    "        alphat - alpha at t\n",
    "    '''\n",
    "    alphat = at + bt\n",
    "    return alphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_grad(fpt,gfpt,fnt,gfnt,yt,pt,at,bt,alphat):\n",
    "    '''\n",
    "    Gradient with respect to w\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        gfpt - positive function gradient at t\n",
    "        fnt - negative function at t\n",
    "        gfnt - negative function gradient at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        alphat - alpha at t\n",
    "    output:\n",
    "        gradwt - gradient w.r.t. w at t\n",
    "    '''\n",
    "    gradwt = 0.0\n",
    "    if yt == 1:\n",
    "        gradwt = (2*alphat*(1-pt) + 2*(1-pt)*(fpt-at) - 2*(1-pt)*fpt)*gfpt\n",
    "    else:\n",
    "        gradwt = (2*alphat*pt + 2*pt*(fnt-bt) - 2*pt*fnt)*gfnt\n",
    "    return gradwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(wt,R):\n",
    "    '''\n",
    "    Projection\n",
    "    \n",
    "    input:\n",
    "        wt - w at t\n",
    "        R - radius\n",
    "        \n",
    "    output:\n",
    "        proj - projected wt\n",
    "    '''\n",
    "    norm = np.linalg.norm(wt)\n",
    "    if norm > R:\n",
    "        wt = wt/norm*R\n",
    "    return wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_grad(fpt,yt,pt,at):\n",
    "    '''\n",
    "    Gradient with respect to a\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "    \n",
    "    output:\n",
    "        gradat - gradient w.r.t a at t\n",
    "    '''\n",
    "    gradat = 0.0 \n",
    "    if yt == 1:\n",
    "        gradat = -2*(1-pt)*(fpt-at)\n",
    "    else:\n",
    "        pass\n",
    "    return gradat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_grad(fnt,yt,pt,bt):\n",
    "    '''\n",
    "    Gradient with respect to b\n",
    "    \n",
    "    input:\n",
    "        fnt - negative function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        bt - b at t\n",
    "    \n",
    "    output:\n",
    "        gradbt - gradient w.r.t b at t\n",
    "    '''\n",
    "    gradbt = 0.0 \n",
    "    if yt == 1:\n",
    "        pass\n",
    "    else:\n",
    "        gradbt = -2*pt*(fnt-bt)\n",
    "    return gradbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj(pt,fpt,fnt,at,bt,alphat,yt):\n",
    "    '''\n",
    "    Compute objective function value\n",
    "    \n",
    "    input:\n",
    "        t - iteration\n",
    "        pt - \n",
    "        wt - \n",
    "    \n",
    "    output:\n",
    "        F - objective funciton value\n",
    "    '''\n",
    "    F = 0.0\n",
    "    if yt == 1:\n",
    "        F = -pt*(1-pt)*alphat**2 + 2*alphat*(1-pt)*fpt+(1-pt)*(fpt-at)**2 - (1-pt)*fpt**2\n",
    "    else:\n",
    "        F = -pt*(1-pt)*alphat**2 + 2*alphat*pt*fnt+pt*(fnt-bt)**2 - pt*fnt**2\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOLAM(t,batch,loss,pt,wt,at,bt,alphat):\n",
    "    '''\n",
    "    Stochastic Online AUC Maximization step\n",
    "    \n",
    "    input:\n",
    "        T - total number of iteration\n",
    "        F - objective function value\n",
    "        loss - loss function\n",
    "        pt - p at t\n",
    "        wt - w at t\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        alphat - alpha at t\n",
    "    output:\n",
    "        W - record of each wt\n",
    "        A - record of each at\n",
    "        B - record of each bt\n",
    "        ALPHA - record of each alphat\n",
    "    '''\n",
    "    # Loop in the batch\n",
    "    eta = 1/np.sqrt(t+1)/2\n",
    "    for k in range(batch):\n",
    "        \n",
    "        # Update pt\n",
    "        pt = p_hat(t*batch+k,y[(t*batch+k)%M],pt)\n",
    "        # Update wt,at,bt\n",
    "        prod = np.inner(wt,x[(t*batch+k)%M])\n",
    "        fpt = np.zeros(N+1)\n",
    "        gfpt = np.zeros(N+1)\n",
    "        fnt = np.zeros(N+1)\n",
    "        gfnt = np.zeros(N+1)\n",
    "        gradwt = 0.0\n",
    "        gradat = 0.0\n",
    "        gradbt = 0.0\n",
    "        \n",
    "        \n",
    "        for i in range(N+1): # add up info of each i\n",
    "            fpt[i],gfpt[i] = pos(i,t,prod) # partial info\n",
    "            fnt[i],gfnt[i] = neg(loss,i,t,prod)\n",
    "            gradwt += w_grad(fpt[i],gfpt[i],fnt[i],gfnt[i],y[(t*batch+k)%M],pt,at,bt,alphat)\n",
    "            gradat += a_grad(fpt[i],y[(t*batch+k)%M],pt,at)\n",
    "            gradbt += b_grad(fnt[i],y[(t*batch+k)%M],pt,bt)\n",
    "            #F += obj(pt,fpt[i],fnt[i],at,bt,alphat,y[(t*batch+k)%T])\n",
    "        \n",
    "        wt -= eta*gradwt*y[(t*batch+k)%M]*x[(t*batch+k)%M]/(N+1)/batch # step size as 1/t gradient descent\n",
    "        \n",
    "        at -= eta*gradat/(N+1)/batch\n",
    "        bt -= eta*gradbt/(N+1)/batch\n",
    "        \n",
    "    wt = proj(wt,10)    \n",
    "    alphat = at+bt\n",
    "        \n",
    "    return pt,wt,at,bt,alphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(filename):\n",
    "    '''\n",
    "    Data file loader\n",
    "    \n",
    "    input:\n",
    "        filename - filename\n",
    "    \n",
    "    output:\n",
    "        x - sample features\n",
    "        y - sample labels\n",
    "    '''\n",
    "    # raw data\n",
    "    raw_df = pd.read_csv(filename,header=None,sep = '\\s+|:',engine='python')\n",
    "    y = raw_df[0].values\n",
    "    x = raw_df[raw_df.columns[2::2]].values\n",
    "    # avoid nan\n",
    "    x = np.nan_to_num(x)\n",
    "    # normalize\n",
    "    norm = np.linalg.norm(x,axis=1)\n",
    "    x = x/norm[:,None]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = loader('diabetes')\n",
    "M,d = x.shape\n",
    "L = 2 # range\n",
    "N = 10 # degree\n",
    "T = 100 # iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangzhenhuan/PycharmProjects/AUC/venv/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/yangzhenhuan/PycharmProjects/AUC/venv/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/yangzhenhuan/PycharmProjects/AUC/venv/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/yangzhenhuan/PycharmProjects/AUC/venv/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/yangzhenhuan/PycharmProjects/AUC/venv/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/yangzhenhuan/PycharmProjects/AUC/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/yangzhenhuan/PycharmProjects/AUC/venv/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: overflow encountered in double_scalars\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d13bcf73871f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSOLAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhinge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mwt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration: %d AUC: %f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/AUC/venv/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \"\"\"\n\u001b[1;32m    612\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 613\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/AUC/venv/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/AUC/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/AUC/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "hinge = lambda x:max(0,1+L-2*L*x)\n",
    "logistics = lambda x:np.log(1+np.exp(L-2*L*x))\n",
    "\n",
    "pt = 0.0\n",
    "wt = np.array([-0.2787, -1.3806, 0.0921, 0.1194, 0.2354, -0.9507, -0.2740, -0.2391])\n",
    "wt = proj(wt,1)\n",
    "at = 0.0\n",
    "bt = 0.0\n",
    "alphat = 0.0\n",
    "\n",
    "roc_auc = np.zeros(T)\n",
    "batch = M\n",
    "for t in range(T):\n",
    "    pt,wt,at,bt,alphat = SOLAM(t,batch,hinge,pt,wt,at,bt,alphat)\n",
    "    fpr, tpr, _ = roc_curve(y, np.dot(x,wt))\n",
    "    roc_auc[t] = auc(fpr, tpr)\n",
    "    print('iteration: %d AUC: %f' %(t+1,roc_auc[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52555648, -0.36963292, -0.18480046,  0.62176063,  0.85058953,\n",
       "        0.00652455,  0.67558177,  0.58147296])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
