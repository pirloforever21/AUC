{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "#import torch\n",
    "from math import factorial\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(i,prod):\n",
    "    '''\n",
    "    Compute positive function and gradient information\n",
    "    \n",
    "    input:\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fpt - positive function value\n",
    "        gfpt - positive function gradient\n",
    "    '''\n",
    "    fpt = 0.0 \n",
    "    gfpt = 0.0 \n",
    "    fpt = (L/2+prod)**i \n",
    "    gfpt = i*(L/2+prod)**(i-1) # no xt yet!\n",
    "    return fpt,gfpt               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(n, k):\n",
    "    '''\n",
    "    Compute combination\n",
    "    \n",
    "    input:\n",
    "        n - total number\n",
    "        k - number of chosen\n",
    "    \n",
    "    output:\n",
    "        c - number of combination\n",
    "    '''\n",
    "    return factorial(n) / factorial(k) / factorial(n - k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(loss,i,prod):\n",
    "    '''\n",
    "    Compute negative function and gradient information\n",
    "    \n",
    "    input:\n",
    "        loss - loss function\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fnt - negative function value\n",
    "        gfnt - negative function gradient\n",
    "    '''\n",
    "    fnt = 0.0 # n stands for negative\n",
    "    gfnt = 0.0\n",
    "    for k in range(i,N+1):\n",
    "        # compute forward difference\n",
    "        delta = 0.0\n",
    "        for j in range(k+1):\n",
    "            delta += (-1)**(k-j)*comb(k,j)*loss(j/N)\n",
    "        # compute coefficient\n",
    "        beta = comb(N,k)*comb(k,i)*(N+1)*delta/(2*L)**k\n",
    "        # compute function value\n",
    "        fnt += beta*(L/2-prod)**(k-i)\n",
    "        # compute gradient\n",
    "        gfnt += beta*(k-i)*(L/2-prod)**(k-i-1)  # no xt yet!\n",
    "    return fnt,gfnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_grad(gfpt,gfnt,yt,at,bt,alphat):\n",
    "    '''\n",
    "    Gradient with respect to w\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        gfpt - positive function gradient at t\n",
    "        fnt - negative function at t\n",
    "        gfnt - negative function gradient at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        alphat - alpha at t\n",
    "    output:\n",
    "        gradwt - gradient w.r.t. w at t\n",
    "    '''\n",
    "    gradwt = 0.0\n",
    "    if yt == 1:\n",
    "        gradwt = 2*(alphat - at)*gfpt\n",
    "    else:\n",
    "        gradwt = 2*(alphat - bt)*gfnt\n",
    "    return gradwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(wt,R):\n",
    "    '''\n",
    "    Projection\n",
    "    \n",
    "    input:\n",
    "        wt - w at t\n",
    "        R - radius\n",
    "        \n",
    "    output:\n",
    "        proj - projected wt\n",
    "    '''\n",
    "    norm = np.linalg.norm(wt)\n",
    "    if norm > R:\n",
    "        wt = wt/norm*R\n",
    "    return wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_grad(fpt,yt,at):\n",
    "    '''\n",
    "    Gradient with respect to a\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "    \n",
    "    output:\n",
    "        gradat - gradient w.r.t a at t\n",
    "    '''\n",
    "    gradat = 0.0 \n",
    "    if yt == 1:\n",
    "        gradat = 2*(at - fpt)\n",
    "    else:\n",
    "        gradat = 2*at\n",
    "    return gradat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_grad(fnt,yt,bt):\n",
    "    '''\n",
    "    Gradient with respect to b\n",
    "    \n",
    "    input:\n",
    "        fnt - negative function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        bt - b at t\n",
    "    \n",
    "    output:\n",
    "        gradbt - gradient w.r.t b at t\n",
    "    '''\n",
    "    gradbt = 0.0 \n",
    "    if yt == 1:\n",
    "        gradbt = 2*bt\n",
    "    else:\n",
    "        gradbt = 2*(bt - fnt)\n",
    "    return gradbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_grad(fpt,fnt,yt,alphat):\n",
    "    '''\n",
    "    Gradient with respect to alpha\n",
    "    '''\n",
    "    gradalphat = 0.0\n",
    "    if yt == 1:\n",
    "        gradalphat = -2*(alphat - fpt)\n",
    "    else:\n",
    "        gradalphat = -2*(alphat - fnt)\n",
    "    return gradalphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(filename):\n",
    "    '''\n",
    "    Data file loader\n",
    "    \n",
    "    input:\n",
    "        filename - filename\n",
    "    \n",
    "    output:\n",
    "        x - sample features\n",
    "        y - sample labels\n",
    "    '''\n",
    "    # raw data\n",
    "    L = []\n",
    "    with open(filename,'r') as file:\n",
    "        for line in csv.reader(file, delimiter = ' '):\n",
    "            line[0] = '0:'+line[0]\n",
    "            line.remove('')\n",
    "            L.append(dict(i.split(':') for i in line))\n",
    "    df = pd.DataFrame(L,dtype=float).fillna(0)\n",
    "    X = df.iloc[:,1:].values\n",
    "    Y = df.iloc[:,0].values\n",
    "    # normalize\n",
    "    norm = np.linalg.norm(X,axis=1)\n",
    "    X = X/norm[:,None]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox(eta,loss,wj,aj,bj,alphaj,bwt,bat,bbt,balphat,x,y):\n",
    "    '''\n",
    "    perform proximal guided gradient descent when receive an sample\n",
    "    '''\n",
    "    prod = np.inner(wj,x)\n",
    "    fpt = np.zeros(N+1)\n",
    "    gfpt = np.zeros(N+1)\n",
    "    fnt = np.zeros(N+1)\n",
    "    gfnt = np.zeros(N+1)\n",
    "    aJ = np.zeros(N+1)\n",
    "    bJ = np.zeros(N+1)\n",
    "    alphaJ = np.zeros(N+1)\n",
    "    gradwt = 0.0\n",
    "    gradat = 0.0\n",
    "    gradbt = 0.0\n",
    "    fval = 0.0\n",
    "    for i in range(N+1):\n",
    "        fpt[i],gfpt[i] = pos(i,prod)\n",
    "        fnt[i],gfnt[i] = neg(loss,i,prod)\n",
    "        gradwt += w_grad(gfpt[i],gfnt[i],y,aj[i],bj[i],alphaj[i]) # accumulate i\n",
    "        gradat = a_grad(fpt[i],y,aj[i])\n",
    "        gradbt = b_grad(fnt[i],y,bj[i])\n",
    "        gradalphat = alpha_grad(fpt[i],fnt[i],y,alphaj[i])\n",
    "        aJ[i] = aj[i] - eta*(gradat/(N+1)+gamma*(aj[i]-bat[i]))\n",
    "        bJ[i] = bj[i] - eta*(gradbt/(N+1)+gamma*(bj[i]-bbt[i]))\n",
    "        #alphaJ[i] = aJ[i] + bJ[i]\n",
    "        alphaJ[i] = alphaj[i] + eta*gradalphat/(N+1)\n",
    "    wJ = wj - eta*(gradwt*x*y/(N+1) + l*wj + gamma*(wj - bwt))\n",
    "    wJ = proj(wJ,np.sqrt(1/l))\n",
    "    #aJ = proj(aJ,1)\n",
    "    #bJ = proj(bJ,1)\n",
    "    #alphaJ = proj(alphaJ,1)\n",
    "    \n",
    "    return wJ,aJ,bJ,alphaJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGSPD(t,loss,X,Y,bwt,bat,bbt,balphat):\n",
    "    '''\n",
    "    Proximally Guided Stochastic Primal Dual Algorithm\n",
    "    '''\n",
    "    \n",
    "    # initialize inner loop variables\n",
    "    Wt = bwt+0.0\n",
    "    At = bat+0.0\n",
    "    Bt = bbt+0.0\n",
    "    ALPHAt = balphat+0.0\n",
    "    \n",
    "    BWt = Wt+0.0\n",
    "    BAt = At+0.0\n",
    "    BBt = Bt+0.0\n",
    "    BALPHAt = ALPHAt+0.0\n",
    "    \n",
    "    ETAt = 1/np.sqrt(t)/M # M is the bound for gradient\n",
    "    # inner loop update at j\n",
    "    for j in range(1,t+1): \n",
    "        # update inner loop variables\n",
    "        Wt,At,Bt,ALPHAt = prox(ETAt,loss,Wt,At,Bt,ALPHAt,bwt,bat,bbt,balphat,X[j-1],Y[j-1])\n",
    "        BWt += Wt\n",
    "        BAt += At\n",
    "        BBt += Bt\n",
    "        BALPHAt += ALPHAt\n",
    "        \n",
    "    # update outer loop variables\n",
    "    bwt = BWt/t\n",
    "    bat = BAt/t\n",
    "    bbt = BBt/t\n",
    "    balphat = BALPHAt/t\n",
    "    \n",
    "    return bwt,bat,bbt,balphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOLAM(t,batch,X,Y,loss,wt,at,bt,alphat):\n",
    "    '''\n",
    "    Stochastic Online AUC Maximization step\n",
    "    \n",
    "    input:\n",
    "        T - total number of iteration\n",
    "        F - objective function value\n",
    "        loss - loss function\n",
    "        pt - p at t\n",
    "        wt - w at t\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        alphat - alpha at t\n",
    "    output:\n",
    "        W - record of each wt\n",
    "        A - record of each at\n",
    "        B - record of each bt\n",
    "        ALPHA - record of each alphat\n",
    "    '''\n",
    "    # Loop in the batch\n",
    "    peta = 1/t/2\n",
    "    deta = 10*np.sqrt(np.log(T)/T)\n",
    "    for k in range(batch):\n",
    "        \n",
    "        # Update wt,at,bt\n",
    "        prod = np.inner(wt,X[k])\n",
    "        fpt = np.zeros(N+1)\n",
    "        gfpt = np.zeros(N+1)\n",
    "        fnt = np.zeros(N+1)\n",
    "        gfnt = np.zeros(N+1)\n",
    "        gradwt = 0.0\n",
    "        gradat = 0.0\n",
    "        gradbt = 0.0\n",
    "        gradalphat = 0.0\n",
    "        \n",
    "        for i in range(N+1): # add up info of each i\n",
    "            fpt[i],gfpt[i] = pos(i,prod) # partial info\n",
    "            fnt[i],gfnt[i] = neg(loss,i,prod)\n",
    "            gradwt += w_grad(gfpt[i],gfnt[i],Y[k],at[i],bt[i],alphat[i])\n",
    "            gradat = a_grad(fpt[i],Y[k],at[i])\n",
    "            gradbt = b_grad(fnt[i],Y[k],bt[i])\n",
    "            gradalphat = alpha_grad(fpt[i],fnt[i],Y[k],alphat[i])\n",
    "            at[i] -= deta*gradat/(N+1)/batch\n",
    "            bt[i] -= deta*gradbt/(N+1)/batch\n",
    "            alphat[i] += deta*gradalphat/(N+1)/batch\n",
    "        \n",
    "        wt = wt - peta*(gradwt*Y[k]*X[k]/(N+1)/batch + l*wt) # step size as 1/t gradient descent\n",
    "        \n",
    "    wt = proj(wt,1/l)    \n",
    "        \n",
    "    return wt,at,bt,alphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinge = lambda x:max(0,1+L-2*L*x)\n",
    "logistic = lambda x:np.log(1+np.exp(L-2*L*x))\n",
    "square = lambda x:(1+L-2*L*x)**2\n",
    "\n",
    "L = 2\n",
    "N = 10\n",
    "M = .1 # weak convexity parameter\n",
    "gamma = 1\n",
    "\n",
    "batch = 1\n",
    "\n",
    "T = 200 # DO NOT make it longer than n!\n",
    "l = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(dataset,loss,alg):\n",
    "    '''\n",
    "    Run it to get results\n",
    "    '''\n",
    "    FEATURES,LABELS = loader(dataset)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(FEATURES, LABELS, test_size=0.2, random_state=0)\n",
    "\n",
    "    # get dimensions of the data\n",
    "    n,d = X_train.shape\n",
    "    \n",
    "    # initialize outer loop variables\n",
    "    WT = np.zeros(d) # d is the dimension of the features\n",
    "    AT = np.zeros(N+1)\n",
    "    BT = np.zeros(N+1)\n",
    "    ALPHAT = np.zeros(N+1)\n",
    "\n",
    "    roc_auc = np.zeros(T)\n",
    "    for t in range(1,T+1):\n",
    "        if alg == 'PGSPD':\n",
    "            # sample a point\n",
    "            index = np.random.randint(n, size=t)\n",
    "            #start = (t*(t-1)//2)%n\n",
    "            #end = (t*(t+1)//2)%n\n",
    "            features = FEATURES[index,:]\n",
    "            labels = LABELS[index]\n",
    "            # update outer loop variables\n",
    "            WT,AT,BT,ALPHAT = PGSPD(t,loss,features,labels,WT,AT,BT,ALPHAT)\n",
    "        elif alg == 'SOLAM':\n",
    "            x_train = X_train[(t*batch)%n:((t+1)*batch)%n]\n",
    "            y_train = Y_train[(t*batch)%n:((t+1)*batch)%n]\n",
    "            WT,AT,BT,ALPHAT = SOLAM(t,batch,x_train,y_train,loss,WT,AT,BT,ALPHAT)\n",
    "        fpr, tpr, _ = roc_curve(Y_test, np.dot(X_test,WT))\n",
    "        roc_auc[t-1] = auc(fpr, tpr)\n",
    "        if t%10 == 0:\n",
    "            print('iteration: %d AUC: %f' %(t,roc_auc[t-1]))\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10 AUC: 0.701730\n",
      "iteration: 20 AUC: 0.661563\n",
      "iteration: 30 AUC: 0.722808\n",
      "iteration: 40 AUC: 0.809704\n",
      "iteration: 50 AUC: 0.814078\n",
      "iteration: 60 AUC: 0.828196\n",
      "iteration: 70 AUC: 0.834361\n",
      "iteration: 80 AUC: 0.841519\n",
      "iteration: 90 AUC: 0.856234\n",
      "iteration: 100 AUC: 0.850865\n",
      "iteration: 110 AUC: 0.854245\n",
      "iteration: 120 AUC: 0.852257\n",
      "iteration: 130 AUC: 0.854643\n",
      "iteration: 140 AUC: 0.857029\n",
      "iteration: 150 AUC: 0.852655\n",
      "iteration: 160 AUC: 0.852257\n",
      "iteration: 170 AUC: 0.861205\n",
      "iteration: 180 AUC: 0.855438\n",
      "iteration: 190 AUC: 0.851064\n",
      "iteration: 200 AUC: 0.851064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x111be4ba8>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetes = demo('diabetes',hinge,'SOLAM')\n",
    "plt.plot(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
