{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "#import torch\n",
    "from math import factorial\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(i,prod):\n",
    "    '''\n",
    "    Compute positive function and gradient information\n",
    "    \n",
    "    input:\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fpt - positive function value\n",
    "        gfpt - positive function gradient\n",
    "    '''\n",
    "    fpt = 0.0 \n",
    "    gfpt = 0.0 \n",
    "    fpt = (L/2+prod)**i \n",
    "    gfpt = i*(L/2+prod)**(i-1) # no xt yet!\n",
    "    return fpt,gfpt               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(n, k):\n",
    "    '''\n",
    "    Compute combination\n",
    "    \n",
    "    input:\n",
    "        n - total number\n",
    "        k - number of chosen\n",
    "    \n",
    "    output:\n",
    "        c - number of combination\n",
    "    '''\n",
    "    return factorial(n) / factorial(k) / factorial(n - k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(loss,i,prod):\n",
    "    '''\n",
    "    Compute negative function and gradient information\n",
    "    \n",
    "    input:\n",
    "        loss - loss function\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fnt - negative function value\n",
    "        gfnt - negative function gradient\n",
    "    '''\n",
    "    fnt = 0.0 # n stands for negative\n",
    "    gfnt = 0.0\n",
    "    for k in range(i,N+1):\n",
    "        # compute forward difference\n",
    "        delta = 0.0\n",
    "        for j in range(k+1):\n",
    "            delta += (-1)**(k-j)*comb(k,j)*loss(j/N)\n",
    "        # compute coefficient\n",
    "        beta = comb(N,k)*comb(k,i)*(N+1)*delta/(2*L)**k\n",
    "        # compute function value\n",
    "        fnt += beta*(L/2-prod)**(k-i)\n",
    "        # compute gradient\n",
    "        gfnt += beta*(k-i)*(L/2-prod)**(k-i-1)  # no xt yet!\n",
    "    return fnt,gfnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_grad(gfpt,gfnt,yt,at,bt,alphat):\n",
    "    '''\n",
    "    Gradient with respect to w\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        gfpt - positive function gradient at t\n",
    "        fnt - negative function at t\n",
    "        gfnt - negative function gradient at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        alphat - alpha at t\n",
    "    output:\n",
    "        gradwt - gradient w.r.t. w at t\n",
    "    '''\n",
    "    gradwt = 0.0\n",
    "    if yt == 1:\n",
    "        gradwt = 2*(alphat - at)*gfpt\n",
    "    else:\n",
    "        gradwt = 2*(alphat - bt)*gfnt\n",
    "    return gradwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(wt,R):\n",
    "    '''\n",
    "    Projection\n",
    "    \n",
    "    input:\n",
    "        wt - w at t\n",
    "        R - radius\n",
    "        \n",
    "    output:\n",
    "        proj - projected wt\n",
    "    '''\n",
    "    norm = np.linalg.norm(wt)\n",
    "    if norm > R:\n",
    "        wt = wt/norm*R\n",
    "    return wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_grad(fpt,yt,at):\n",
    "    '''\n",
    "    Gradient with respect to a\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "    \n",
    "    output:\n",
    "        gradat - gradient w.r.t a at t\n",
    "    '''\n",
    "    gradat = 0.0 \n",
    "    if yt == 1:\n",
    "        gradat = 2*(at - fpt)\n",
    "    else:\n",
    "        gradat = 2*at\n",
    "    return gradat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_grad(fnt,yt,bt):\n",
    "    '''\n",
    "    Gradient with respect to b\n",
    "    \n",
    "    input:\n",
    "        fnt - negative function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        bt - b at t\n",
    "    \n",
    "    output:\n",
    "        gradbt - gradient w.r.t b at t\n",
    "    '''\n",
    "    gradbt = 0.0 \n",
    "    if yt == 1:\n",
    "        gradbt = 2*bt\n",
    "    else:\n",
    "        gradbt = 2*(bt - fnt)\n",
    "    return gradbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_grad(fpt,fnt,yt,alphat):\n",
    "    '''\n",
    "    Gradient with respect to alpha\n",
    "    '''\n",
    "    gradalphat = 0.0\n",
    "    if yt == 1:\n",
    "        gradalphat = -2*(alphat - fpt)\n",
    "    else:\n",
    "        gradalphat = -2*(alphat - fnt)\n",
    "    return gradalphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(filename):\n",
    "    '''\n",
    "    Data file loader\n",
    "    \n",
    "    input:\n",
    "        filename - filename\n",
    "    \n",
    "    output:\n",
    "        x - sample features\n",
    "        y - sample labels\n",
    "    '''\n",
    "    # raw data\n",
    "    L = []\n",
    "    with open(filename,'r') as file:\n",
    "        for line in csv.reader(file, delimiter = ' '):\n",
    "            line[0] = '0:'+line[0]\n",
    "            line.remove('')\n",
    "            L.append(dict(i.split(':') for i in line))\n",
    "    df = pd.DataFrame(L,dtype=float).fillna(0)\n",
    "    X = df.iloc[:,1:].values\n",
    "    Y = df.iloc[:,0].values\n",
    "    # centralize\n",
    "    mean = np.mean(X,axis=1)\n",
    "    #X = (X.transpose() - mean).transpose()\n",
    "    # normalize\n",
    "    norm = np.linalg.norm(X,axis=1)\n",
    "    #X = X/norm[:,None]\n",
    "    # convert to binary class\n",
    "    r = np.ptp(Y)\n",
    "    index = np.argwhere(Y<r//2)\n",
    "    INDEX = np.argwhere(Y>=r//2)\n",
    "    Y[index] = -1\n",
    "    Y[INDEX] = 1\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox(eta,loss,wj,aj,bj,alphaj,bwt,bat,bbt,balphat,x,y):\n",
    "    '''\n",
    "    perform proximal guided gradient descent when receive an sample\n",
    "    '''\n",
    "    prod = np.inner(wj,x)\n",
    "    fpt = np.zeros(N+1)\n",
    "    gfpt = np.zeros(N+1)\n",
    "    fnt = np.zeros(N+1)\n",
    "    gfnt = np.zeros(N+1)\n",
    "    aJ = np.zeros(N+1)\n",
    "    bJ = np.zeros(N+1)\n",
    "    alphaJ = np.zeros(N+1)\n",
    "    gradwt = 0.0\n",
    "    gradat = 0.0\n",
    "    gradbt = 0.0\n",
    "    fval = 0.0\n",
    "    for i in range(N+1):\n",
    "        fpt[i],gfpt[i] = pos(i,prod)\n",
    "        fnt[i],gfnt[i] = neg(loss,i,prod)\n",
    "        gradwt += w_grad(gfpt[i],gfnt[i],y,aj[i],bj[i],alphaj[i]) # accumulate i\n",
    "        gradat = a_grad(fpt[i],y,aj[i])\n",
    "        gradbt = b_grad(fnt[i],y,bj[i])\n",
    "        gradalphat = alpha_grad(fpt[i],fnt[i],y,alphaj[i])\n",
    "        aJ[i] = aj[i] - eta*(gradat/(N+1)+gamma*(aj[i]-bat[i]))\n",
    "        bJ[i] = bj[i] - eta*(gradbt/(N+1)+gamma*(bj[i]-bbt[i]))\n",
    "        #alphaJ[i] = aJ[i] + bJ[i]\n",
    "        alphaJ[i] = alphaj[i] + eta*gradalphat/(N+1)\n",
    "    wJ = wj - eta*(gradwt*x*y/(N+1) + l*wj + gamma*(wj - bwt))\n",
    "    wJ = proj(wJ,np.sqrt(1/l))\n",
    "    #aJ = proj(aJ,1)\n",
    "    #bJ = proj(bJ,1)\n",
    "    #alphaJ = proj(alphaJ,1)\n",
    "    \n",
    "    return wJ,aJ,bJ,alphaJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGSPD(t,loss,X,Y,bwt,bat,bbt,balphat):\n",
    "    '''\n",
    "    Proximally Guided Stochastic Primal Dual Algorithm\n",
    "    '''\n",
    "    \n",
    "    # initialize inner loop variables\n",
    "    Wt = bwt+0.0\n",
    "    At = bat+0.0\n",
    "    Bt = bbt+0.0\n",
    "    ALPHAt = balphat+0.0\n",
    "    \n",
    "    BWt = Wt+0.0\n",
    "    BAt = At+0.0\n",
    "    BBt = Bt+0.0\n",
    "    BALPHAt = ALPHAt+0.0\n",
    "    \n",
    "    ETAt = 1/np.sqrt(t)/M # M is the bound for gradient\n",
    "    # inner loop update at j\n",
    "    for j in range(1,t+1): \n",
    "        # update inner loop variables\n",
    "        Wt,At,Bt,ALPHAt = prox(ETAt,loss,Wt,At,Bt,ALPHAt,bwt,bat,bbt,balphat,X[j-1],Y[j-1])\n",
    "        BWt += Wt\n",
    "        BAt += At\n",
    "        BBt += Bt\n",
    "        BALPHAt += ALPHAt\n",
    "        \n",
    "    # update outer loop variables\n",
    "    bwt = BWt/t\n",
    "    bat = BAt/t\n",
    "    bbt = BBt/t\n",
    "    balphat = BALPHAt/t\n",
    "    \n",
    "    return bwt,bat,bbt,balphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOLAM(t,batch,X,Y,loss,wt,at,bt,alphat):\n",
    "    '''\n",
    "    Stochastic Online AUC Maximization step\n",
    "    \n",
    "    input:\n",
    "        T - total number of iteration\n",
    "        F - objective function value\n",
    "        loss - loss function\n",
    "        pt - p at t\n",
    "        wt - w at t\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        alphat - alpha at t\n",
    "    output:\n",
    "        W - record of each wt\n",
    "        A - record of each at\n",
    "        B - record of each bt\n",
    "        ALPHA - record of each alphat\n",
    "    '''\n",
    "    # Loop in the batch\n",
    "    peta = 1/t/2\n",
    "    deta = np.sqrt(np.log(T)/T)\n",
    "    for k in range(batch):\n",
    "        \n",
    "        # Update wt,at,bt\n",
    "        prod = np.dot(wt,X[k])\n",
    "        fpt = np.zeros(N+1)\n",
    "        gfpt = np.zeros(N+1)\n",
    "        fnt = np.zeros(N+1)\n",
    "        gfnt = np.zeros(N+1)\n",
    "        gradwt = 0.0\n",
    "        gradat = 0.0\n",
    "        gradbt = 0.0\n",
    "        gradalphat = 0.0\n",
    "        \n",
    "        for i in range(N+1): # add up info of each i\n",
    "            fpt[i],gfpt[i] = pos(i,prod) # partial info\n",
    "            fnt[i],gfnt[i] = neg(loss,i,prod)\n",
    "            gradwt += w_grad(gfpt[i],gfnt[i],Y[k],at[i],bt[i],alphat[i])\n",
    "            gradat = a_grad(fpt[i],Y[k],at[i])\n",
    "            gradbt = b_grad(fnt[i],Y[k],bt[i])\n",
    "            gradalphat = alpha_grad(fpt[i],fnt[i],Y[k],alphat[i])\n",
    "            at[i] -= deta*gradat/(N+1)/batch\n",
    "            bt[i] -= deta*gradbt/(N+1)/batch\n",
    "            alphat[i] += deta*gradalphat/(N+1)/batch\n",
    "        \n",
    "        wt = wt - peta*(gradwt*Y[k]*X[k]/(N+1)/batch + l*wt) # step size as 1/t gradient descent\n",
    "        \n",
    "    #wt = proj(wt,1/l)    \n",
    "        \n",
    "    return wt,at,bt,alphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinge = lambda x:max(0,1+L-2*L*x)\n",
    "logistic = lambda x:np.log(1+np.exp(L-2*L*x))\n",
    "square = lambda x:(1+L-2*L*x)**2\n",
    "\n",
    "N = 20\n",
    "L = 2\n",
    "M = .1 # weak convexity parameter\n",
    "gamma = 1\n",
    "\n",
    "batch = 1\n",
    "\n",
    "T = 200 \n",
    "l = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(dataset,loss,alg):\n",
    "    '''\n",
    "    Run it to get results\n",
    "    '''\n",
    "    FEATURES,LABELS = loader(dataset)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(FEATURES, LABELS, test_size=0.2, random_state=0)\n",
    "\n",
    "    # get dimensions of the data\n",
    "    n,d = X_train.shape\n",
    "    \n",
    "    # initialize outer loop variables\n",
    "    WT = np.zeros(d) # d is the dimension of the features\n",
    "    AT = np.zeros(N+1)\n",
    "    BT = np.zeros(N+1)\n",
    "    ALPHAT = np.zeros(N+1)\n",
    "\n",
    "    roc_auc = np.zeros(T)\n",
    "    for t in range(1,T+1):\n",
    "        if alg == 'PGSPD':\n",
    "            # sample a point\n",
    "            index = np.random.randint(n, size=t)\n",
    "            features = FEATURES[index,:]\n",
    "            labels = LABELS[index]\n",
    "            # update outer loop variables\n",
    "            WT,AT,BT,ALPHAT = PGSPD(t,loss,features,labels,WT,AT,BT,ALPHAT)\n",
    "        elif alg == 'SOLAM':\n",
    "            start = (t*batch)%n\n",
    "            end = ((t+1)*batch)%n\n",
    "            if start < end:\n",
    "                x_train = X_train[start:end]\n",
    "                y_train = Y_train[start:end]\n",
    "            else: # need to think better\n",
    "                x_train = np.append(X_train[start:],X_train[:end],axis=0)\n",
    "                y_train = np.append(Y_train[start:],Y_train[:end],axis=0)\n",
    "            WT,AT,BT,ALPHAT = SOLAM(t,batch,x_train,y_train,loss,WT,AT,BT,ALPHAT)\n",
    "        fpr, tpr, _ = roc_curve(Y_test, np.dot(X_test,WT))\n",
    "        roc_auc[t-1] = auc(fpr, tpr)\n",
    "        if t%100 == 0:\n",
    "            print('iteration: %d AUC: %f' %(t,roc_auc[t-1]))\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 100 AUC: 0.853052\n",
      "iteration: 200 AUC: 0.839531\n",
      "iteration: 300 AUC: 0.845496\n",
      "iteration: 400 AUC: 0.846689\n",
      "iteration: 500 AUC: 0.840127\n",
      "iteration: 600 AUC: 0.833764\n",
      "iteration: 700 AUC: 0.841121\n",
      "iteration: 800 AUC: 0.838536\n",
      "iteration: 900 AUC: 0.845297\n",
      "iteration: 1000 AUC: 0.843905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f81464dac50>]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 1000\n",
    "diabetes = demo('diabetes',hinge,'SOLAM')\n",
    "plt.plot(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
