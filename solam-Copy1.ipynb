{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from itertools import product\n",
    "import multiprocessing\n",
    "from math import sqrt,log,exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(i,prod,L):\n",
    "    '''\n",
    "    Compute positive function and gradient information\n",
    "    \n",
    "    input:\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fpt - positive function value\n",
    "        gfpt - positive function gradient\n",
    "    '''\n",
    "    plus = L/2+prod\n",
    "    fpt = plus**i\n",
    "    gfpt = fpt*i/plus # no xt yet!\n",
    "    \n",
    "    # hfpt = i*(i-1)*(L/2+prod)**(i-2)\n",
    "    return fpt,gfpt              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(n, k):\n",
    "    '''\n",
    "    Compute combination\n",
    "    \n",
    "    input:\n",
    "        n - total number\n",
    "        k - number of chosen\n",
    "    \n",
    "    output:\n",
    "        c - number of combination\n",
    "    '''\n",
    "    return factorial(n) / factorial(k) / factorial(n - k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_dict = {0:{0:1},1:{0:1,1:1},2:{0:1,1:2,2:1},3:{0:1,1:3,2:3,3:1},4:{0:1,1:4,2:6,3:4,4:1},\n",
    "             5:{0:1,1:5,2:10,3:10,4:5,5:1},6:{0:1,1:6,2:15,3:20,4:15,5:6,6:1},\n",
    "             7:{0:1,1:7,2:21,3:35,4:35,5:21,6:7,7:1},8:{0:1,1:8,2:28,3:56,4:70,5:56,6:28,7:8,8:1},\n",
    "             9:{0:1,1:9,2:36,3:84,4:126,5:126,6:84,7:36,8:9,9:1},\n",
    "             10:{0:1,1:10,2:45,3:120,4:210,5:252,6:210,7:120,8:45,9:10,10:1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_dict = {0:np.array([11,110,495,1320,2310,2772,2310,1320,495,110,11]),\n",
    "             1:np.array([110,990,3960,9240,13860,13860,9240,3960,990,110]),\n",
    "             2:np.array([495,3960,13860,27720,34650,27720,13860,3960,495]),\n",
    "             3:np.array([1320,9240,27720,46200,46200,27720,9240,1320]),\n",
    "             4:np.array([2310,13860,34650,46200,34650,13860,2310]),5:np.array([2772,13860,27720,27720,13860,2772]),\n",
    "             6:np.array([2310,9240,13860,9240,2310]),7:np.array([1320,3960,3960,1320]),8:np.array([495,990,495]),\n",
    "             9:np.array([110,110]),10:np.array([11])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(loss,i,prod,L):\n",
    "    '''\n",
    "    Compute negative function and gradient information\n",
    "    \n",
    "    input:\n",
    "        loss - loss function\n",
    "        i - index of function\n",
    "        t - iteration\n",
    "        prod - wt*xt\n",
    "        \n",
    "    output:\n",
    "        fnt - negative function value\n",
    "        gfnt - negative function gradient\n",
    "    '''\n",
    "    minus = L/2-prod\n",
    "    #FNT = np.zeros(N+1-i)\n",
    "    #GFNT = np.zeros(N+1-i)\n",
    "    fnt = 0.0\n",
    "    gfnt = 0.0\n",
    "    # hfnt = 0.0\n",
    "    for k in range(i,N+1):\n",
    "        # compute forward difference\n",
    "        delta = 0.0\n",
    "        for j in range(k+1):\n",
    "            delta += comb_dict[k][j]*(-1)**(k-j)*loss(j/N)\n",
    "            \n",
    "        # compute coefficient\n",
    "        #beta = beta_dict[i][k-i]*delta/(2*L)**k*minus**(k-i)\n",
    "        beta = comb_dict[N][k]*comb_dict[k][i]*(N+1)*delta/(2*L)**k*minus**(k-i)\n",
    "        # compute function value\n",
    "        fnt += beta\n",
    "        # compute gradient\n",
    "        gfnt += beta*(k-i)/minus  # no xt yet!\n",
    "        '''\n",
    "        # compute temp function value\n",
    "        FNT[k-i] = delta/(2*L)**k*(minus**(k-i))\n",
    "        GFNT[k-i] = FNT[k-i]*(k-i)/minus\n",
    "    # compute function value\n",
    "    fnt = np.dot(beta_dict[i],FNT)\n",
    "    # compute gradient\n",
    "    gfnt = np.dot(beta_dict[i],GFNT) # no xt yet!\n",
    "    '''\n",
    "        # compute hessian\n",
    "        # hfnt += beta*(k-i)*(k-i-1)*(L/2-prod)**(k-i-2)\n",
    "    return fnt,gfnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_grad(gfpt,gfnt,yt,at,bt,alphat):\n",
    "    '''\n",
    "    Gradient with respect to w\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        gfpt - positive function gradient at t\n",
    "        fnt - negative function at t\n",
    "        gfnt - negative function gradient at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        alphat - alpha at t\n",
    "    output:\n",
    "        gradwt - gradient w.r.t. w at t\n",
    "    '''\n",
    "    if yt == 1:\n",
    "        gradwt = 2*(alphat - at)*gfpt\n",
    "    else:\n",
    "        gradwt = 2*(alphat - bt)*gfnt\n",
    "    return gradwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_hess(hfpt,hfnt,yt,at,bt,alphat):\n",
    "    hesswt = 0.0\n",
    "    if yt == 1:\n",
    "        hesswt = 2*(alphat - at)*hfpt\n",
    "    else:\n",
    "        hesswt = 2*(alphat - bt)*hfnt\n",
    "    return hesswt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(wt,R):\n",
    "    '''\n",
    "    Projection\n",
    "    \n",
    "    input:\n",
    "        wt - w at t\n",
    "        R - radius\n",
    "        \n",
    "    output:\n",
    "        proj - projected wt\n",
    "    '''\n",
    "    norm = np.linalg.norm(wt)\n",
    "    if norm > R:\n",
    "        wt = wt/norm*R\n",
    "    return wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_grad(fpt,yt,at):\n",
    "    '''\n",
    "    Gradient with respect to a\n",
    "    \n",
    "    input:\n",
    "        fpt - positive function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        at - a at t\n",
    "    \n",
    "    output:\n",
    "        gradat - gradient w.r.t a at t\n",
    "    '''\n",
    "    gradat = 0.0 \n",
    "    if yt == 1:\n",
    "        gradat = 2*(at - fpt)\n",
    "    else:\n",
    "        gradat = 2*at\n",
    "    return gradat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_grad(fnt,yt,bt):\n",
    "    '''\n",
    "    Gradient with respect to b\n",
    "    \n",
    "    input:\n",
    "        fnt - negative function at t\n",
    "        yt - sample label at t\n",
    "        pt - p at t\n",
    "        bt - b at t\n",
    "    \n",
    "    output:\n",
    "        gradbt - gradient w.r.t b at t\n",
    "    '''\n",
    "    gradbt = 0.0 \n",
    "    if yt == 1:\n",
    "        gradbt = 2*bt\n",
    "    else:\n",
    "        gradbt = 2*(bt - fnt)\n",
    "    return gradbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_grad(fpt,fnt,yt,alphat):\n",
    "    '''\n",
    "    Gradient with respect to alpha\n",
    "    '''\n",
    "    gradalphat = 0.0\n",
    "    if yt == 1:\n",
    "        gradalphat = -2*(alphat - fpt)\n",
    "    else:\n",
    "        gradalphat = -2*(alphat - fnt)\n",
    "    return gradalphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(filename):\n",
    "    '''\n",
    "    Data file loader\n",
    "    \n",
    "    input:\n",
    "        filename - filename\n",
    "    \n",
    "    output:\n",
    "        x - sample features\n",
    "        y - sample labels\n",
    "    '''\n",
    "    # raw data\n",
    "    L = []\n",
    "    with open(filename,'r') as file:\n",
    "        for line in csv.reader(file, delimiter = ' '):\n",
    "            line[0] = '0:'+line[0]\n",
    "            line.remove('')\n",
    "            L.append(dict(i.split(':') for i in line))\n",
    "    df = pd.DataFrame(L,dtype=float).fillna(0)\n",
    "    X = df.iloc[:,1:].values\n",
    "    Y = df.iloc[:,0].values\n",
    "    # centralize\n",
    "    mean = np.mean(X,axis=1)\n",
    "    X = (X.transpose() - mean).transpose()\n",
    "    # normalize\n",
    "    norm = np.linalg.norm(X,axis=1)\n",
    "    X = X/norm[:,None]\n",
    "    # convert to binary class\n",
    "    r = np.ptp(Y).astype(int)\n",
    "    index = np.argwhere(Y<=r//2)\n",
    "    INDEX = np.argwhere(Y>r//2)\n",
    "    Y[index] = -1\n",
    "    Y[INDEX] = 1\n",
    "    Y = Y.astype(int)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(FEATURES,LABELS,folder,folders):\n",
    "    \n",
    "    if folder > folders:\n",
    "        print('Exceed maximum folders!')\n",
    "        return\n",
    "    # load and split data\n",
    "    #FEATURES,LABELS = loader(dataset)\n",
    "    n,d = FEATURES.shape\n",
    "    # regular portion of each folder\n",
    "    portion = round(n/folders)\n",
    "    start = portion*folder\n",
    "    stop = portion*(folder+1)\n",
    "    if np.abs(stop - n) < portion: # remainder occurs\n",
    "        X_train = FEATURES[:start,:]\n",
    "        Y_train = LABELS[:start]\n",
    "        X_test = FEATURES[start:,:]\n",
    "        Y_test = LABELS[start:]\n",
    "    else:\n",
    "        mask = np.ones(n, bool)\n",
    "        mask[start:stop] = False\n",
    "        X_train = FEATURES[mask,:]\n",
    "        Y_train = LABELS[mask]\n",
    "        X_test = FEATURES[start:stop]\n",
    "        Y_test = LABELS[start:stop]\n",
    "    # get dimensions of the data\n",
    "    # n,_ = X_train.shape\n",
    "    # number of epoch\n",
    "    # epoch = T//n+1\n",
    "    # augment by epoch\n",
    "    # X_train_augmented = np.tile(X_train,(epoch,1)) # might have memory burden\n",
    "    # Y_train_augmented = np.tile(Y_train,epoch)\n",
    "    \n",
    "    #return X_train_augmented,X_test,Y_train_augmented,Y_test\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox(eta,loss,x,y,L,gamma,lam,wj,aj,bj,alphaj,bwt,bat,bbt,balphat):\n",
    "    '''\n",
    "    perform proximal guided gradient descent when receive an sample\n",
    "    '''\n",
    "    prod = np.dot(wj,x)\n",
    "    fpt = np.zeros(N+1)\n",
    "    gfpt = np.zeros(N+1)\n",
    "    # hfpt = np.zeros(N+1)\n",
    "    fnt = np.zeros(N+1)\n",
    "    gfnt = np.zeros(N+1)\n",
    "    # hfnt = np.zeros(N+1)\n",
    "    gradwt = 0.0\n",
    "    gradat = 0.0\n",
    "    gradbt = 0.0\n",
    "    gradalphat = 0.0\n",
    "    # hesswt = 0.0\n",
    "    for i in range(N+1):\n",
    "        fpt[i],gfpt[i] = pos(i,prod,L)\n",
    "        #print(fpt[i])\n",
    "        fnt[i],gfnt[i] = neg(loss,i,prod,L)\n",
    "        gradwt += w_grad(gfpt[i],gfnt[i],y,aj[i],bj[i],alphaj[i])# accumulate i\n",
    "        # hesswt += w_hess(hfpt[i],hfnt[i],y,aj[i],bj[i],alphaj[i])\n",
    "        gradat = a_grad(fpt[i],y,aj[i])\n",
    "        gradbt = b_grad(fnt[i],y,bj[i])\n",
    "        gradalphat = alpha_grad(fpt[i],fnt[i],y,alphaj[i])\n",
    "        aj[i] = aj[i] - eta*(gradat/(N+1)+gamma*(aj[i]-bat[i]))\n",
    "        bj[i] = bj[i] - eta*(gradbt/(N+1)+gamma*(bj[i]-bbt[i]))\n",
    "        alphaj[i] = alphaj[i] + eta*gradalphat/(N+1)\n",
    "    # hessian = hesswt*np.outer(x,x)\n",
    "    # eigen,_ = np.linalg.eig(hessian)\n",
    "    \n",
    "    # print('minimum eigenvalue: %f' %(np.min(eigen)))\n",
    "    wj = wj - eta*(gradwt*x*y/(N+1) + lam*wj + gamma*(wj - bwt))\n",
    "    wj = proj(wj,L/2)\n",
    "    #aJ = proj(aJ,1)\n",
    "    #bJ = proj(bJ,1)\n",
    "    #alphaJ = proj(alphaJ,1)\n",
    "    \n",
    "    return wj,aj,bj,alphaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGSPD(t,loss,X,Y,L,gamma,lam,theta,c,bwt,bat,bbt,balphat):\n",
    "    '''\n",
    "    Proximally Guided Stochastic Primal Dual Algorithm\n",
    "    '''\n",
    "    \n",
    "    # initialize inner loop variables\n",
    "    Wt = bwt+0.0\n",
    "    At = bat+0.0\n",
    "    Bt = bbt+0.0\n",
    "    ALPHAt = balphat+0.0\n",
    "    \n",
    "    BWt = Wt+0.0\n",
    "    BAt = At+0.0\n",
    "    BBt = Bt+0.0\n",
    "    BALPHAt = ALPHAt+0.0\n",
    "    \n",
    "    ETAt = c/(t**theta)\n",
    "    # inner loop update at j\n",
    "    for j in range(t): \n",
    "        # update inner loop variables\n",
    "        Wt,At,Bt,ALPHAt = prox(ETAt,loss,X[j],Y[j],L,gamma,lam,Wt,At,Bt,ALPHAt,bwt,bat,bbt,balphat)\n",
    "        BWt += Wt\n",
    "        BAt += At\n",
    "        BBt += Bt\n",
    "        BALPHAt += ALPHAt\n",
    "        \n",
    "    # update outer loop variables\n",
    "    bwt = BWt/t\n",
    "    bat = BAt/t\n",
    "    bbt = BBt/t\n",
    "    balphat = BALPHAt/t\n",
    "    \n",
    "    return bwt,bat,bbt,balphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOLAM(t,loss,batch,X,Y,L,lam,theta,c,wt,at,bt,alphat):\n",
    "    '''\n",
    "    Stochastic Online AUC Maximization step\n",
    "    \n",
    "    input:\n",
    "        T - total number of iteration\n",
    "        F - objective function value\n",
    "        loss - loss function\n",
    "        pt - p at t\n",
    "        wt - w at t\n",
    "        at - a at t\n",
    "        bt - b at t\n",
    "        alphat - alpha at t\n",
    "    output:\n",
    "        W - record of each wt\n",
    "        A - record of each at\n",
    "        B - record of each bt\n",
    "        ALPHA - record of each alphat\n",
    "    '''\n",
    "    # Loop in the batch\n",
    "    peta = c/(t**theta)\n",
    "    deta = sqrt(log(T*(T+1)/2/batch)/(T*(T+1)/2/batch))\n",
    "    for k in range(batch):\n",
    "        \n",
    "        # Update wt,at,bt\n",
    "        prod = np.dot(wt,X[k])\n",
    "        fpt = np.zeros(N+1)\n",
    "        gfpt = np.zeros(N+1)\n",
    "        fnt = np.zeros(N+1)\n",
    "        gfnt = np.zeros(N+1)\n",
    "        gradwt = 0.0\n",
    "        gradat = 0.0\n",
    "        gradbt = 0.0\n",
    "        gradalphat = 0.0\n",
    "        \n",
    "        for i in range(N+1): # add up info of each i\n",
    "            fpt[i],gfpt[i] = pos(i,prod,L) # partial info\n",
    "            fnt[i],gfnt[i] = neg(loss,i,prod,L)\n",
    "            gradwt += w_grad(gfpt[i],gfnt[i],Y[k],at[i],bt[i],alphat[i])\n",
    "            gradat = a_grad(fpt[i],Y[k],at[i])\n",
    "            gradbt = b_grad(fnt[i],Y[k],bt[i])\n",
    "            gradalphat = alpha_grad(fpt[i],fnt[i],Y[k],alphat[i])\n",
    "            at[i] -= deta*gradat/(N+1)/batch\n",
    "            bt[i] -= deta*gradbt/(N+1)/batch\n",
    "            alphat[i] += deta*gradalphat/(N+1)/batch\n",
    "        \n",
    "        wt = wt - peta*(gradwt*Y[k]*X[k]/(N+1)/batch + lam*wt) # step size as 1/t gradient descent\n",
    "        \n",
    "    wt = proj(wt,L/2)    \n",
    "        \n",
    "    return wt,at,bt,alphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(X_train_augmented,X_test,Y_train_augmented,Y_test,loss,alg,gamma=0.1,lam=1.0,theta=0.1,c = 1.0):\n",
    "    '''\n",
    "    Run it to get results\n",
    "    '''\n",
    "    # define loss function\n",
    "    if loss == 'hinge':\n",
    "        L = 2*sqrt(2/lam)\n",
    "        loss = lambda x: max(0,1+L-2*L*x)\n",
    "    elif loss == 'logistic':\n",
    "        L = 2*sqrt(2*log(2)/lam)\n",
    "        loss = lambda x:log(1+exp(L-2*L*x))\n",
    "    else:\n",
    "        print('Wrong loss function!')\n",
    "        return\n",
    "    \n",
    "    # get dimensions of the data\n",
    "    num,d = X_train_augmented.shape\n",
    "    \n",
    "    # initialize outer loop variables\n",
    "    WT = np.zeros(d) # d is the dimension of the features\n",
    "    AT = np.zeros(N+1)\n",
    "    BT = np.zeros(N+1)\n",
    "    ALPHAT = np.zeros(N+1)\n",
    "\n",
    "    # record auc\n",
    "    roc_auc = np.zeros(T)\n",
    "    # record time elapsed\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for t in range(1,T+1):    \n",
    "        if alg == 'PGSPD':\n",
    "        \n",
    "            if t<num:\n",
    "                begin = (t*(t-1)//2)%num\n",
    "                end = (t*(t+1)//2)%num\n",
    "                if begin < end:\n",
    "                    x_train = X_train_augmented[begin:end]\n",
    "                    y_train = Y_train_augmented[begin:end]\n",
    "                else: # need to think better\n",
    "                    x_train = np.append(X_train_augmented[begin:],X_train_augmented[:end],axis=0)\n",
    "                    y_train = np.append(Y_train_augmented[begin:],Y_train_augmented[:end],axis=0)\n",
    "                # print(sum(x_train))\n",
    "                x_train, y_train = shuffle(x_train,y_train)\n",
    "                # update outer loop variables\n",
    "                WT,AT,BT,ALPHAT = PGSPD(t,loss,x_train,y_train,L,gamma,lam,theta,c,WT,AT,BT,ALPHAT)\n",
    "            else:\n",
    "                x_train, y_train = shuffle(X_train_augmented,Y_train_augmented)\n",
    "                WT,AT,BT,ALPHAT = PGSPD(num,loss,x_train,y_train,L,gamma,lam,theta,c,WT,AT,BT,ALPHAT)\n",
    "                \n",
    "        elif alg == 'SOLAM':\n",
    "\n",
    "            # sample a point\n",
    "            begin = (t-1)*batch%num\n",
    "            end = t*batch%num\n",
    "            if begin < end:\n",
    "                x_train = X_train_augmented[begin:end]\n",
    "                y_train = Y_train_augmented[begin:end]\n",
    "            else: # need to think better\n",
    "                x_train = np.append(X_train_augmented[begin:],X_train_augmented[:end],axis=0)\n",
    "                y_train = np.append(Y_train_augmented[begin:],Y_train_augmented[:end],axis=0)\n",
    "            WT,AT,BT,ALPHAT = SOLAM(t,loss,batch,x_train,y_train,L,lam,theta,c,WT,AT,BT,ALPHAT)\n",
    "        \n",
    "        else:\n",
    "            print('Wrong algorithm!')\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            fpr, tpr, _ = roc_curve(Y_test, np.dot(X_test,WT))\n",
    "            roc_auc[t-1] = auc(fpr, tpr)\n",
    "        except RuntimeWarning:\n",
    "            print('Something is wrong bruh! Look at sum of WT: %f' %(sum(WT)))\n",
    "            return WT,AT,BT,ALPHAT,roc_auc\n",
    "        if t%100 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('gamma: %.2f lam: %.2f theta: %.2f c: %.2f iteration: %d AUC: %.2f time eplapsed: %.2f' \n",
    "                  %(gamma,lam,theta,c,t,roc_auc[t-1],elapsed_time))\n",
    "            start_time = time.time()\n",
    "    \n",
    "            \n",
    "    return WT,AT,BT,ALPHAT,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(dataset,loss,alg,folders,gamma=0.0,lam=0.0,theta=1.0,c=1.0):\n",
    "    '''\n",
    "    Cross validation\n",
    "    '''\n",
    "    # Load data set\n",
    "    FEATURES,LABELS = loader(dataset) \n",
    "    \n",
    "    # record auc\n",
    "    AUC_ROC = np.zeros(folders)\n",
    "    \n",
    "    # cross validation\n",
    "    for folder in range(folders):\n",
    "        print('folder = %d' %(folder))\n",
    "        X_train_augmented,X_test,Y_train_augmented,Y_test = split(FEATURES,LABELS,folder,folders)\n",
    "        \n",
    "        _,_,_,_,roc_auc = demo(X_train_augmented,X_test,Y_train_augmented,Y_test,loss,alg,gamma=gamma,lam=lam,theta=theta,c=c)\n",
    "        AUC_ROC[folder] = max(roc_auc)\n",
    "    print('auc score: %f +/- %f' %(np.mean(AUC_ROC),np.std(AUC_ROC)))\n",
    "    return AUC_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_run(para):\n",
    "    folder,gamma,lam,theta,c,paras = para\n",
    "    X_train_augmented,X_test,Y_train_augmented, Y_test,loss,alg = paras\n",
    "    _,_,_,_,roc_auc = demo(X_train_augmented,X_test,Y_train_augmented,Y_test,loss,alg\n",
    "                           ,gamma=GAMMA[gamma],lam=LAM[lam],theta=THETA[theta],c=C[c])\n",
    "    return folder,gamma,lam,theta,c, np.max(roc_auc)\n",
    "    \n",
    "def gs(dataset,loss,alg,folders,GAMMA=[0.0],LAM=[0.0],THETA=[1.0],C=[1.0]):\n",
    "    '''\n",
    "    Grid search! Wuss up fellas?!\n",
    "    And we are using multiprocessing, fancy!\n",
    "    '''\n",
    "    # number of cpu want to use\n",
    "    num_cpus = 15\n",
    "    # Load data set\n",
    "    FEATURES,LABELS = loader(dataset) \n",
    "    # record auc\n",
    "    AUC_ROC = np.zeros((folders,len(GAMMA),len(LAM),len(THETA),len(C)))\n",
    "    # record parameters\n",
    "    input_paras = []\n",
    "    # grid search prepare\n",
    "    for folder in range(folders):\n",
    "        X_train_augmented,X_test,Y_train_augmented,Y_test = split(FEATURES,LABELS,folder,folders)\n",
    "        paras = X_train_augmented,X_test,Y_train_augmented, Y_test,loss,alg\n",
    "        for gamma,lam,theta,c in product(range(len(GAMMA)),range(len(LAM)),range(len(THETA)),range(len(C))):\n",
    "            input_paras.append((folder,gamma,lam,theta,c,paras))\n",
    "    print('how many paras: %d' % len(input_paras))\n",
    "    # grid search run on multiprocessors\n",
    "    pool = multiprocessing.Pool(processes=num_cpus)\n",
    "    results_pool = pool.map(single_run,input_paras)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    # save results\n",
    "    for folder,gamma,lam,theta,c, auc_roc in results_pool:\n",
    "        AUC_ROC[folder,gamma,lam,theta,c] = auc_roc\n",
    "    MEAN = np.zeros((len(GAMMA),len(LAM),len(THETA),len(C)))\n",
    "    STD = np.zeros((len(GAMMA),len(LAM),len(THETA),len(C)))\n",
    "    for gamma,lam,theta,c in product(range(len(GAMMA)),range(len(LAM)),range(len(THETA)),range(len(C))):    \n",
    "        MEAN[gamma,lam,theta,c] = np.mean(AUC_ROC[:,gamma,lam,theta,c])\n",
    "        STD[gamma,lam,theta,c] = np.std(AUC_ROC[:,gamma,lam,theta,c])\n",
    "    return AUC_ROC,MEAN,STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10\n",
    "T=200\n",
    "batch=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = [0.01]\n",
    "LAM = [10]\n",
    "THETA = [0.25]\n",
    "C = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many paras: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:643: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:114: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(dx < 0):\n",
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:643: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:114: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(dx < 0):\n",
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:643: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:114: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(dx < 0):\n",
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:643: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:114: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(dx < 0):\n",
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:643: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "/home/neyo/PycharmProjects/AUC/venv/lib/python3.5/site-packages/sklearn/metrics/ranking.py:114: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(dx < 0):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.01 lam: 10.00 theta: 0.25 c: 10.00 iteration: 100 AUC: nan time eplapsed: 12.61\n",
      "gamma: 0.01 lam: 10.00 theta: 0.25 c: 10.00 iteration: 100 AUC: nan time eplapsed: 18.46\n",
      "gamma: 0.01 lam: 10.00 theta: 0.25 c: 10.00 iteration: 100 AUC: nan time eplapsed: 19.00\n",
      "gamma: 0.01 lam: 10.00 theta: 0.25 c: 10.00 iteration: 100 AUC: nan time eplapsed: 19.89\n",
      "gamma: 0.01 lam: 10.00 theta: 0.25 c: 10.00 iteration: 100 AUC: nan time eplapsed: 19.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-1:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-2:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-12:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-5:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-20-84100d25d341>\", line 5, in single_run\n",
      "    ,gamma=GAMMA[gamma],lam=LAM[lam],theta=THETA[theta],c=C[c])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"<ipython-input-20-84100d25d341>\", line 5, in single_run\n",
      "    ,gamma=GAMMA[gamma],lam=LAM[lam],theta=THETA[theta],c=C[c])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-20-84100d25d341>\", line 5, in single_run\n",
      "    ,gamma=GAMMA[gamma],lam=LAM[lam],theta=THETA[theta],c=C[c])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-18-1091d36901de>\", line 45, in demo\n",
      "    WT,AT,BT,ALPHAT = PGSPD(t,loss,x_train,y_train,L,gamma,lam,theta,c,WT,AT,BT,ALPHAT)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-18-1091d36901de>\", line 45, in demo\n",
      "    WT,AT,BT,ALPHAT = PGSPD(t,loss,x_train,y_train,L,gamma,lam,theta,c,WT,AT,BT,ALPHAT)\n",
      "  File \"<ipython-input-16-8fe792301771>\", line 21, in PGSPD\n",
      "    Wt,At,Bt,ALPHAt = prox(ETAt,loss,X[j],Y[j],L,gamma,lam,Wt,At,Bt,ALPHAt,bwt,bat,bbt,balphat)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-15-4097c1d9a577>\", line 20, in prox\n",
      "    fnt[i],gfnt[i] = neg(loss,i,prod,L)\n",
      "  File \"<ipython-input-6-418faf4458ea>\", line 25, in neg\n",
      "    delta += comb_dict[k][j]*(-1)**(k-j)*loss(j/N)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-18-1091d36901de>\", line 45, in demo\n",
      "    WT,AT,BT,ALPHAT = PGSPD(t,loss,x_train,y_train,L,gamma,lam,theta,c,WT,AT,BT,ALPHAT)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-20-84100d25d341>\", line 5, in single_run\n",
      "    ,gamma=GAMMA[gamma],lam=LAM[lam],theta=THETA[theta],c=C[c])\n",
      "  File \"<ipython-input-18-1091d36901de>\", line 8, in <lambda>\n",
      "    loss = lambda x: max(0,1+L-2*L*x)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-18-1091d36901de>\", line 45, in demo\n",
      "    WT,AT,BT,ALPHAT = PGSPD(t,loss,x_train,y_train,L,gamma,lam,theta,c,WT,AT,BT,ALPHAT)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-16-8fe792301771>\", line 21, in PGSPD\n",
      "    Wt,At,Bt,ALPHAt = prox(ETAt,loss,X[j],Y[j],L,gamma,lam,Wt,At,Bt,ALPHAt,bwt,bat,bbt,balphat)\n",
      "  File \"<ipython-input-16-8fe792301771>\", line 21, in PGSPD\n",
      "    Wt,At,Bt,ALPHAt = prox(ETAt,loss,X[j],Y[j],L,gamma,lam,Wt,At,Bt,ALPHAt,bwt,bat,bbt,balphat)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-15-4097c1d9a577>\", line 20, in prox\n",
      "    fnt[i],gfnt[i] = neg(loss,i,prod,L)\n",
      "  File \"<ipython-input-6-418faf4458ea>\", line 29, in neg\n",
      "    beta = comb_dict[N][k]*comb_dict[k][i]*(N+1)*delta/(2*L)**k*minus**(k-i)\n",
      "  File \"<ipython-input-16-8fe792301771>\", line 21, in PGSPD\n",
      "    Wt,At,Bt,ALPHAt = prox(ETAt,loss,X[j],Y[j],L,gamma,lam,Wt,At,Bt,ALPHAt,bwt,bat,bbt,balphat)\n",
      "  File \"<ipython-input-15-4097c1d9a577>\", line 27, in prox\n",
      "    bj[i] = bj[i] - eta*(gradbt/(N+1)+gamma*(bj[i]-bbt[i]))\n",
      "  File \"<ipython-input-20-84100d25d341>\", line 5, in single_run\n",
      "    ,gamma=GAMMA[gamma],lam=LAM[lam],theta=THETA[theta],c=C[c])\n",
      "  File \"<ipython-input-15-4097c1d9a577>\", line 20, in prox\n",
      "    fnt[i],gfnt[i] = neg(loss,i,prod,L)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-18-1091d36901de>\", line 45, in demo\n",
      "    WT,AT,BT,ALPHAT = PGSPD(t,loss,x_train,y_train,L,gamma,lam,theta,c,WT,AT,BT,ALPHAT)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-6-418faf4458ea>\", line 25, in neg\n",
      "    delta += comb_dict[k][j]*(-1)**(k-j)*loss(j/N)\n",
      "  File \"<ipython-input-16-8fe792301771>\", line 21, in PGSPD\n",
      "    Wt,At,Bt,ALPHAt = prox(ETAt,loss,X[j],Y[j],L,gamma,lam,Wt,At,Bt,ALPHAt,bwt,bat,bbt,balphat)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-15-4097c1d9a577>\", line 20, in prox\n",
      "    fnt[i],gfnt[i] = neg(loss,i,prod,L)\n",
      "  File \"<ipython-input-6-418faf4458ea>\", line 29, in neg\n",
      "    beta = comb_dict[N][k]*comb_dict[k][i]*(N+1)*delta/(2*L)**k*minus**(k-i)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5dcc1f86fd07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macoustic_hinge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macoustic_hinge_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musps_hinge_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acoustic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hinge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PGSPD'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLAM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTHETA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total elapsed time: %f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrun_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-84100d25d341>\u001b[0m in \u001b[0;36mgs\u001b[0;34m(dataset, loss, alg, folders, GAMMA, LAM, THETA, C)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# grid search run on multiprocessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mresults_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_paras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_time = time.time()\n",
    "acoustic_hinge,acoustic_hinge_mean,usps_hinge_std = gs('acoustic','hinge','PGSPD',5,GAMMA,LAM,THETA,C)\n",
    "print('total elapsed time: %f' %(time.time() - run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
